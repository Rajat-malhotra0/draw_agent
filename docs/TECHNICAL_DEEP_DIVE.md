# Draw Agent - Complete Technical Documentation

##  Overview

Draw Agent is an AI-powered interactive canvas where users can draw math problems and an LLM (Llama 4 Scout via Groq API) analyzes the image, solves the problem, and draws the solution back onto the canvas in real-time.

---

##  System Architecture

```

                         DRAW AGENT SYSTEM                            


                  
   FRONTEND                    BACKEND                   GROQ API       
  (React + Vite)    (Hono + Node)     (Llama 4 Scout) 
  Port: 5173                 Port: 3000                 Vision Model    
                  
                                     
                                     
              WebSocket (Socket.IO)  
        
            Real-time Drawing        
                                     
```

---

##  Complete User Flow

```
USER INTERACTION FLOW


1. USER DRAWS ON CANVAS
   
     User draws: "7 + 11 ="
   
   

  Canvas Component (Frontend)    
  - Captures mouse events        
  - Draws on HTML5 Canvas        
  - Stores drawing in canvas     

   
     User clicks "Solve" button
   
   

2. CANVAS TO IMAGE CONVERSION
   
   

  solveCanvas() function         
  - Converts canvas to base64    
  - const imageData =            
    canvas.toDataURL('image/png')

   
     POST /api/ai/solve
     { image: "data:image/png;base64,..." }
   
   

3. BACKEND RECEIVES IMAGE
   
   

  ai.routes.js                   
  - Validates image data         
  - Checks API key               

   
     Calls solveMathProblem()
   
   

4. GROQ API CALL
   
   

  groqService.js                 
  - Prepares vision prompt       
  - Sends image to Llama 4 Scout 
  - Model analyzes drawing       

   
     Returns: "The answer is 18"
   
   

5. ANSWER EXTRACTION
   
   

  Answer Parsing Logic           
  - Regex patterns extract "18"  
  - Cleans formatting            

   
     Extracted: "18"
   
   

6. DRAWING COMMANDS VIA WEBSOCKET
   
   

  Socket.IO Broadcasting         
  - Emits 'llm-draw' events      
  - Sends drawing commands       
  - Timed with setTimeout        

   
     io.emit('llm-draw', {action, data})
   
   

7. FRONTEND RECEIVES & RENDERS
   
   

  Canvas WebSocket Listener      
  - Receives drawing commands    
  - Draws checkmark             
  - Draws "Answer:" label        
  - Draws "18" in blue           

   
     User sees result on canvas!
   
   

8. SOLUTION MODAL DISPLAY
   
   

  showSolution() function        
  - Creates modal overlay        
  - Shows full explanation       
  - User clicks "Close"          

```

---

##  Code Deep Dive

### 1. Frontend Canvas Component

**File:** `frontend/src/components/Canvas.jsx`

```jsx
// STEP 1: Canvas Setup & WebSocket Connection
useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;

    // Set canvas size to window dimensions
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight - 50;

    const ctx = canvas.getContext("2d");
    ctx.lineCap = "round";
    ctx.lineJoin = "round";
    setContext(ctx);

    // INITIALIZE WEBSOCKET CONNECTION
    socket = io("http://localhost:3000");

    socket.on("connect", () => {
        console.log("Connected to server");
    });

    // LISTEN FOR LLM DRAWING COMMANDS
    socket.on("llm-draw", (data) => {
        handleLLMDraw(ctx, data);
    });

    return () => {
        if (socket) socket.disconnect();
    };
}, []);
```

**WebSocket Drawing Handler:**

```jsx
// STEP 2: Handle Drawing Commands from Backend
const handleLLMDraw = (ctx, { action, data }) => {
    switch(action) {
        case 'line':
            // Draw a line (used for checkmark)
            ctx.beginPath();
            ctx.moveTo(data.from.x, data.from.y);
            ctx.lineTo(data.to.x, data.to.y);
            ctx.strokeStyle = data.color || '#FF6B6B';
            ctx.lineWidth = data.width || 2;
            ctx.stroke();
            break;
            
        case 'text':
            // Draw text (used for answer)
            ctx.font = `${data.size || 16}px Arial`;
            ctx.fillStyle = data.color || '#000000';
            ctx.fillText(data.text, data.x, data.y);
            break;
            
        case 'clear':
            // Clear canvas
            ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
            break;
    }
};
```

**User Drawing:**

```jsx
// STEP 3: User Drawing Interaction
const startDrawing = (e) => {
    if (tool !== "pen" && tool !== "eraser") return;
    
    setIsDrawing(true);
    const rect = canvasRef.current.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    setLastPos({ x, y });
};

const draw = (e) => {
    if (!isDrawing || !context) return;

    const rect = canvasRef.current.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;

    context.beginPath();
    context.moveTo(lastPos.x, lastPos.y);
    context.lineTo(x, y);
    context.strokeStyle = tool === "eraser" ? "#fafafa" : color;
    context.lineWidth = tool === "eraser" ? strokeWidth * 3 : strokeWidth;
    context.stroke();

    setLastPos({ x, y });
};
```

**Solve Function:**

```jsx
// STEP 4: Convert Canvas to Image & Send to Backend
const solveCanvas = async () => {
    if (!canvasRef.current || isProcessing) return;

    setIsProcessing(true);
    try {
        // Convert canvas to base64 PNG image
        const imageData = canvasRef.current.toDataURL("image/png");

        // Send to backend
        const response = await axios.post("/api/ai/solve", {
            image: imageData,
            options: { stepByStep: true },
        });

        if (response.data.success) {
            const { answer } = response.data.solution;
            showSolution(answer);
        }
    } catch (error) {
        console.error("Error:", error);
        alert("Failed to solve: " + error.message);
    } finally {
        setIsProcessing(false);
    }
};
```

---

### 2. Backend API Route

**File:** `backend/src/routes/ai.routes.js`

```javascript
// STEP 5: Backend Receives Image and Processes
app.post('/solve', async (c) => {
    try {
        const body = await c.req.json();
        const { image, options = {} } = body;
        
        // Validate image data
        if (!image) {
            return c.json({
                success: false,
                error: { message: "No image provided" }
            }, 400);
        }

        // Check Groq API key
        if (!process.env.GROQ_API_KEY) {
            return c.json({
                success: false,
                error: { message: "Groq API key not configured" }
            }, 500);
        }

        console.log("Received solve request");
        
        // CALL GROQ SERVICE
        const result = await solveMathProblem(image, options);
        
        // EXTRACT AND DRAW ANSWER ON CANVAS
        if (result.success) {
            const { io } = await import("../server.js");
            const answer = result.solution.answer;

            console.log("Full AI response:", answer);

            // INTELLIGENT ANSWER EXTRACTION
            let finalAnswer = null;
            
            const patterns = [
                /(?:final answer|answer|result|solution)(?:\s+is)?[:\s=]+([^.\n]+)/i,
                /therefore[,:]?\s*([^.\n]+)/i,
                /=\s*([^.\n=]+?)(?:\.|$)/i,
                /^([^.\n]+)$/m,
            ];

            for (const pattern of patterns) {
                const match = answer.match(pattern);
                if (match && match[1]) {
                    finalAnswer = match[1].trim();
                    // Clean formatting
                    finalAnswer = finalAnswer
                        .replace(/\*\*/g, "")      // Remove bold
                        .replace(/^\*+|\*+$/g, "") // Remove asterisks
                        .replace(/^[-]\s*/, "")  // Remove dashes
                        .replace(/\$/g, "")        // Remove $
                        .trim();
                    if (finalAnswer.length > 0 && finalAnswer.length < 50) {
                        break;
                    }
                }
            }

            console.log("Extracted answer:", finalAnswer);

            // ANIMATE CHECKMARK - Part 1
            setTimeout(() => {
                io.emit("llm-draw", {
                    action: "line",
                    data: {
                        from: { x: 50, y: 100 },
                        to: { x: 75, y: 130 },
                        color: "#4CAF50",
                        width: 5,
                    },
                });
            }, 300);

            // ANIMATE CHECKMARK - Part 2
            setTimeout(() => {
                io.emit("llm-draw", {
                    action: "line",
                    data: {
                        from: { x: 75, y: 130 },
                        to: { x: 120, y: 70 },
                        color: "#4CAF50",
                        width: 5,
                    },
                });
            }, 500);

            // DRAW "Answer:" LABEL
            setTimeout(() => {
                io.emit("llm-draw", {
                    action: "text",
                    data: {
                        text: "Answer:",
                        x: 150,
                        y: 100,
                        color: "#666666",
                        size: 20,
                    },
                });
            }, 700);

            // DRAW ACTUAL ANSWER
            setTimeout(() => {
                io.emit("llm-draw", {
                    action: "text",
                    data: {
                        text: finalAnswer,
                        x: 250,
                        y: 100,
                        color: "#1E90FF",
                        size: 28,
                    },
                });
            }, 900);
        }
        
        return c.json(result);
    } catch (error) {
        console.error("Error in /solve:", error);
        return c.json({
            success: false,
            error: { message: error.message }
        }, 500);
    }
});
```

---

### 3. Groq Service (Vision AI)

**File:** `backend/src/services/groqService.js`

```javascript
// STEP 6: Send Image to Groq's Llama 4 Scout Vision Model
export async function solveMathProblem(imageBase64, options = {}) {
    if (!groq) {
        throw new Error('Groq API client not initialized');
    }
    
    try {
        // Prepare image URL
        const imageUrl = imageBase64.startsWith('data:') 
            ? imageBase64 
            : `data:image/png;base64,${imageBase64}`;

        // Create prompt for vision model
        const prompt = options.stepByStep 
            ? 'Analyze this mathematical problem. Solve it step by step and explain your reasoning clearly.'
            : 'Solve this mathematical problem and provide the answer.';

        console.log('Calling Groq API...');
        
        // Define drawing tool (currently Groq may not support tool calling)
        const tools = [{
            type: "function",
            function: {
                name: "draw_on_canvas",
                description: "Draw lines, shapes, or text on the canvas",
                parameters: {
                    type: "object",
                    properties: {
                        action: {
                            type: "string",
                            enum: ["line", "text", "clear"],
                        },
                        data: {
                            type: "object",
                            properties: {
                                from: { 
                                    type: "object",
                                    properties: { x: {type: "number"}, y: {type: "number"} }
                                },
                                to: { 
                                    type: "object",
                                    properties: { x: {type: "number"}, y: {type: "number"} }
                                },
                                text: { type: "string" },
                                x: { type: "number" },
                                y: { type: "number" },
                                color: { type: "string" },
                                width: { type: "number" },
                                size: { type: "number" }
                            }
                        }
                    },
                    required: ["action", "data"]
                }
            }
        }];

        // MAKE API CALL TO GROQ
        const chatCompletion = await groq.chat.completions.create({
            messages: [
                {
                    role: "user",
                    content: [
                        {
                            type: "text",
                            text: prompt
                        },
                        {
                            type: "image_url",
                            image_url: {
                                url: imageUrl
                            }
                        }
                    ]
                }
            ],
            model: "meta-llama/llama-4-scout-17b-16e-instruct", // Vision-capable model
            temperature: options.temperature || 0.3,
            max_completion_tokens: options.maxTokens || 2000,
            top_p: 1,
            stream: false,
            tools: tools,
            tool_choice: "auto"
        });

        const solution = chatCompletion.choices[0].message.content;
        const toolCalls = chatCompletion.choices[0].message.tool_calls;
        
        console.log('Groq API response received');

        return {
            success: true,
            solution: {
                answer: solution,
                steps: parseSteps(solution),
                model: "llama-4-scout-17b-16e-instruct",
                tokensUsed: chatCompletion.usage?.total_tokens || 0,
                toolCalls: toolCalls || []
            }
        };
    } catch (error) {
        console.error('Groq API error:', error.message);
        throw new Error(`Failed to solve problem: ${error.message}`);
    }
}
```

---

### 4. WebSocket Server Setup

**File:** `backend/src/server.js`

```javascript
import { Server } from 'socket.io';

// ... Hono app setup ...

// Start HTTP server
const server = serve({
    fetch: app.fetch,
    port: PORT
});

// INITIALIZE SOCKET.IO
const io = new Server(server, {
    cors: {
        origin: process.env.CORS_ORIGIN || 'http://localhost:5173',
        methods: ['GET', 'POST']
    }
});

// HANDLE WEBSOCKET CONNECTIONS
io.on('connection', (socket) => {
    console.log('Client connected:', socket.id);

    // User drawing events
    socket.on('draw', (data) => {
        socket.broadcast.emit('draw', data);
    });

    // Clear canvas events
    socket.on('clear', () => {
        socket.broadcast.emit('clear');
    });

    // LLM drawing commands
    socket.on('llm-draw', (data) => {
        io.emit('llm-draw', data);
    });

    socket.on('disconnect', () => {
        console.log('Client disconnected:', socket.id);
    });
});

export { io };
```

---

##  Drawing Command Format

### Line Command (for Checkmark)
```javascript
{
    action: 'line',
    data: {
        from: { x: 50, y: 100 },   // Start point
        to: { x: 75, y: 130 },     // End point
        color: '#4CAF50',          // Green
        width: 5                   // Line thickness
    }
}
```

### Text Command (for Answer)
```javascript
{
    action: 'text',
    data: {
        text: '18',                // The answer
        x: 250,                    // X position
        y: 100,                    // Y position
        color: '#1E90FF',          // Blue
        size: 28                   // Font size
    }
}
```

---

##  Animation Timeline

```
Time (ms)    Event

   0         User clicks "Solve"
   +         Canvas converts to image
   +         POST request to /api/ai/solve
   +         Backend calls Groq API (1-3 seconds)

  300         Draw checkmark part 1 (green line)
  500         Draw checkmark part 2 (green line)
  700        Draw "Answer:" label (gray text)
  900        Draw "18" (blue text, size 28)

  900+       Show solution modal with full explanation
```

---

##  Answer Extraction Algorithm

```javascript
/*
  STEP-BY-STEP ANSWER EXTRACTION
  
  
  INPUT: "Step 1: Add 7 + 11\nStep 2: The result is 18\nTherefore, the answer is 18."
  
  Process:
  --------
  1. Try Pattern 1: /answer[:\s=]+([^.\n]+)/i
     Match: "is 18"
     Extract: "18"
  
  2. Clean the extracted text:
     - Remove ** (markdown bold)
     - Remove * (asterisks)
     - Remove $ (dollar signs)
     - Remove leading dashes
     - Trim whitespace
  
  3. Validate:
     - Length > 0
     - Length < 50 (reasonable answer size)
  
  OUTPUT: "18"
*/

const patterns = [
    // Pattern 1: "answer is 18" or "answer: 18"
    /(?:final answer|answer|result|solution)(?:\s+is)?[:\s=]+([^.\n]+)/i,
    
    // Pattern 2: "therefore, 18"
    /therefore[,:]?\s*([^.\n]+)/i,
    
    // Pattern 3: "= 18"
    /=\s*([^.\n=]+?)(?:\.|$)/i,
    
    // Pattern 4: Last line fallback
    /^([^.\n]+)$/m
];

for (const pattern of patterns) {
    const match = answer.match(pattern);
    if (match && match[1]) {
        finalAnswer = match[1].trim()
            .replace(/\*\*/g, "")      // Remove **
            .replace(/^\*+|\*+$/g, "") // Remove *
            .replace(/\$/g, "")        // Remove $
            .trim();
        
        if (finalAnswer.length > 0 && finalAnswer.length < 50) {
            break; // Found valid answer
        }
    }
}
```

---

##  Data Flow Diagram

```

                        DATA FLOW                                     


USER DRAWS "7 + 11 ="
        
        
    [Canvas]
         canvas.toDataURL('image/png')
        
"data:image/png;base64,iVBORw0KGgoAAAANSUhEUg..."
        
         POST /api/ai/solve
        
    [Backend Route]
        
         solveMathProblem(image, options)
        
    [Groq Service]
        
         groq.chat.completions.create({
           messages: [{
             content: [
               { type: "text", text: "Solve this..." },
               { type: "image_url", image_url: { url: imageData } }
             ]
           }],
           model: "meta-llama/llama-4-scout-17b-16e-instruct"
         })
        
    [Llama 4 Scout]
         Vision Model Processes Image
         Recognizes: "7 + 11 ="
        
"## Step 1: Understand the Problem
We need to add 7 and 11.
## Step 2: Calculate
7 + 11 = 18
Therefore, the answer is 18."
        
        
    [Answer Extraction]
         Regex patterns extract
        
    finalAnswer = "18"
        
        
    [WebSocket Broadcast]
        
         io.emit('llm-draw', {action: 'line', ...})  // Checkmark part 1
         io.emit('llm-draw', {action: 'line', ...})  // Checkmark part 2
         io.emit('llm-draw', {action: 'text', ...})  // "Answer:"
         io.emit('llm-draw', {action: 'text', ...})  // "18"
        
        
    [Frontend Canvas]
         socket.on('llm-draw', handleLLMDraw)
        
RENDERS ON CANVAS:
 Answer: 18
```

---

##  Tech Stack Details

### Frontend
```
Technology       Purpose

React 18         UI component framework
Vite 5           Fast build tool & dev server
TanStack Router  Client-side routing
Socket.IO Client WebSocket real-time communication
Axios            HTTP requests to backend
HTML5 Canvas API Drawing and rendering graphics
```

### Backend
```
Technology       Purpose

Hono             Lightweight web framework (Express alternative)
Node.js 18+      JavaScript runtime
Socket.IO        WebSocket server for real-time events
Groq SDK         AI API client for Llama models
dotenv           Environment variable management
```

### AI Model
```
Model                               Capabilities

meta-llama/llama-4-scout-17b-16e    - Vision understanding
-instruct                           - Math problem solving
                                    - Step-by-step reasoning
                                    - Tool calling (experimental)
```

---

##  Deployment Architecture

```
PRODUCTION ARCHITECTURE



      Users        
   (Web Browser)   

           HTTPS
          

   Load Balancer    (nginx / Cloudflare)

          
    
               
               
 
Frontend  Frontend   (Static files: Vercel/Netlify)
Instance  Instance   Port: 443 (HTTPS)
 
               
     WSS        HTTPS
               

  Backend Server     (Node.js: Railway/Render/AWS)
  Hono + Socket.IO   Port: 3000  443

           HTTPS
          

   Groq API          (External Service)
   Llama 4 Scout     https://api.groq.com

```

---

##  Environment Variables

### Backend `.env`
```bash
# Server Configuration
PORT=3000
NODE_ENV=production

# Groq AI API
GROQ_API_KEY=gsk_your_actual_api_key_here

# CORS Settings
CORS_ORIGIN=https://your-frontend-domain.com
```

### Frontend Environment
```bash
# API Endpoint
VITE_API_URL=https://your-backend-domain.com
VITE_WS_URL=wss://your-backend-domain.com
```

---

##  API Reference

### REST Endpoints

#### `POST /api/ai/solve`
Solve a math problem from canvas image.

**Request:**
```json
{
  "image": "data:image/png;base64,iVBORw0KG...",
  "options": {
    "stepByStep": true,
    "temperature": 0.3,
    "maxTokens": 2000
  }
}
```

**Response:**
```json
{
  "success": true,
  "solution": {
    "answer": "Step 1: Understand the Problem...\nThe answer is 18.",
    "steps": [
      { "step": 1, "content": "Understand the Problem" },
      { "step": 2, "content": "7 + 11 = 18" }
    ],
    "model": "llama-4-scout-17b-16e-instruct",
    "tokensUsed": 245,
    "toolCalls": []
  }
}
```

#### `GET /api/ai/test`
Test Groq API connectivity.

**Response:**
```json
{
  "success": true,
  "message": "Hello from Groq!",
  "model": "llama-3.1-8b-instant"
}
```

#### `GET /api/health`
Health check endpoint.

**Response:**
```json
{
  "status": "healthy",
  "timestamp": "2025-10-31T18:00:00.000Z",
  "version": "1.0.0",
  "groqConfigured": true
}
```

#### `POST /api/canvas/draw`
LLM drawing commands (future use).

**Request:**
```json
{
  "action": "line",
  "data": {
    "from": { "x": 100, "y": 100 },
    "to": { "x": 200, "y": 200 },
    "color": "#1E90FF",
    "width": 3
  }
}
```

### WebSocket Events

#### Client  Server
```javascript
// User drawing
socket.emit('draw', {
  from: { x: 100, y: 100 },
  to: { x: 101, y: 101 },
  color: '#000000',
  width: 3
});

// Clear canvas
socket.emit('clear');
```

#### Server  Client
```javascript
// LLM drawing commands
socket.on('llm-draw', (data) => {
  // data = { action: 'line', data: {...} }
  // data = { action: 'text', data: {...} }
});

// Broadcast clear
socket.on('clear', () => {
  // Clear canvas
});
```

---

##  Example Scenarios

### Scenario 1: Simple Addition
```
INPUT:  "2 + 2 ="
        
GROQ:   "To solve 2 + 2:
         Step 1: Add the two numbers
         2 + 2 = 4
         Therefore, the answer is 4."

EXTRACT: "4"

CANVAS:  Answer: 4
```

### Scenario 2: Multiplication
```
INPUT:  "7  11 ="

GROQ:   "## Step 1: Understand the Problem
         We need to multiply 7 by 11.
         
         ## Step 2: Calculate
         7  11 = 77
         
         The final answer is 77."

EXTRACT: "77"

CANVAS:  Answer: 77
```

### Scenario 3: Complex Expression
```
INPUT:  "(8 + 4)  3 ="

GROQ:   "Let's solve step by step:
         1. First, solve the parentheses: 8 + 4 = 12
         2. Then divide by 3: 12  3 = 4
         
         Answer is 4."

EXTRACT: "4"

CANVAS:  Answer: 4
```

---

##  Debugging & Logging

### Backend Logs
```javascript
// In ai.routes.js
console.log("Received solve request");
console.log("Full AI response:", answer);
console.log("Extracted answer:", finalAnswer);

// In groqService.js
console.log('Calling Groq API...');
console.log('Groq API response received');

// In server.js
console.log('Client connected:', socket.id);
console.log('Client disconnected:', socket.id);
```

### Frontend Logs
```javascript
// In Canvas.jsx
console.log("Connected to server");
console.log('Solution received, tool calls:', toolCalls?.length || 0);

// Check WebSocket events
socket.on('llm-draw', (data) => {
  console.log('Received drawing command:', data);
});
```

---

##  Customization Guide

### Change Answer Position
```javascript
// In ai.routes.js, modify coordinates:
setTimeout(() => {
    io.emit("llm-draw", {
        action: "text",
        data: {
            text: finalAnswer,
            x: 300,  //  Change X position
            y: 150,  //  Change Y position
            color: "#1E90FF",
            size: 28,
        },
    });
}, 900);
```

### Change Colors
```javascript
// Checkmark color
color: "#4CAF50",  // Green  Change to any hex color

// Answer color
color: "#1E90FF",  // Blue  Change to any hex color

// Label color
color: "#666666",  // Gray  Change to any hex color
```

### Adjust Animation Speed
```javascript
// Current timing:
setTimeout(() => { /* checkmark 1 */ }, 300);   //  First animation
setTimeout(() => { /* checkmark 2 */ }, 500);   //  Second animation
setTimeout(() => { /* label */ }, 700);         //  Third animation
setTimeout(() => { /* answer */ }, 900);        //  Fourth animation

// For faster animation, decrease numbers
// For slower animation, increase numbers
```

---

##  Performance Metrics

```
Operation            Typical Time  Optimizations

Canvas Drawing       < 1ms         Hardware accelerated
Canvas to Image      50-100ms      PNG compression
HTTP Request         10-50ms       Keep-alive connections
Groq API Call        1-3s          Vision model processing
Answer Extraction    < 1ms         Regex matching
WebSocket Emit       < 5ms         Binary protocol
Canvas Rendering     < 1ms         RequestAnimationFrame
Total (User Click    1.5-4s        Parallel processing
to Answer Drawn)                  
```

---

##  Security Considerations

### API Key Protection
```javascript
//  GOOD: API key in .env file (server-side)
GROQ_API_KEY=gsk_secret_key

//  BAD: Never expose in frontend
const apiKey = "gsk_secret_key";  // Don't do this!
```

### Input Validation
```javascript
// Validate image data
if (!image || !image.startsWith('data:image/')) {
    return c.json({ error: 'Invalid image data' }, 400);
}

// Size limits
if (image.length > 10 * 1024 * 1024) {  // 10MB limit
    return c.json({ error: 'Image too large' }, 400);
}
```

### CORS Configuration
```javascript
// Restrict origins in production
cors: {
    origin: process.env.CORS_ORIGIN || 'http://localhost:5173',
    methods: ['GET', 'POST']
}
```

---

##  Future Enhancements

1. **LLM Tool Calling** - When Groq fully supports it, the LLM can directly call the canvas drawing tool
2. **Multi-user Collaboration** - Multiple users drawing on same canvas
3. **Canvas History** - Undo/redo functionality
4. **Export Solutions** - Save canvas as image or PDF
5. **Voice Input** - Speak the math problem
6. **Step-by-step Visualization** - Animate each solving step
7. **Multiple Canvas Pages** - Work on multiple problems
8. **LaTeX Rendering** - Display mathematical notation beautifully

---

##  Key Takeaways

1. **Vision AI**: Llama 4 Scout analyzes drawings using computer vision
2. **Real-time Communication**: WebSocket enables instant LLM-to-canvas drawing
3. **Smart Parsing**: Regex patterns extract clean answers from AI responses
4. **Animated Feedback**: Timed events create engaging user experience
5. **Modular Design**: Separate concerns (frontend, backend, AI service)
6. **Tool Architecture**: System designed for LLM tool integration

---

**System Status:**  Fully Operational
**Last Updated:** October 31, 2025
**Version:** 1.0.0
